# Pipeline RAG - Standardisation Documentaire (Git-Driven)

> **Architecture automatisÃ©e pour transformer des documents bruts en Markdown enrichi par IA**

---

## Table des matiÃ¨res

1. [Vue d'ensemble](#vue-densemble)
2. [Architecture complÃ¨te](#architecture-complÃ¨te)
3. [Composants dÃ©taillÃ©s](#composants-dÃ©taillÃ©s)
4. [Format de sortie](#format-de-sortie)
5. [Workflow CI/CD](#workflow-cicd)
6. [Organisation repository](#organisation-repository)
7. [DÃ©ploiement](#dÃ©ploiement)

---

## Vue d'ensemble

### Objectif

Automatiser la transformation de documents hÃ©tÃ©rogÃ¨nes (DOCX, PDF, TXT, emails) en documentation Markdown standardisÃ©e, enrichie par LLM, et optimisÃ©e pour l'ingestion RAG.

### Flux simplifiÃ©

```mermaid
flowchart LR
    A[ğŸ“„ Documents bruts<br/>inbox/] --> B[ğŸ¤– Pipeline<br/>Automatique]
    B --> C[ğŸ“š Markdown enrichi<br/>knowledge/]
    C --> D[ğŸ”® RAG]
```

### Principe

- **Input** : L'Ã©quipe dÃ©pose des fichiers dans `inbox/` via Git
- **Processing** : Pipeline automatique (extraction + enrichissement LLM + validation)
- **Output** : Markdown avec mÃ©tadonnÃ©es YAML dans `knowledge/`
- **Trigger** : GitHub Actions (zÃ©ro intervention manuelle)

---

## Architecture complÃ¨te

### Vue d'ensemble des composants

```mermaid
graph TB
    subgraph "ğŸ“¥ INPUT - Zone Humaine"
        User[ğŸ‘¤ Ã‰quipe Support]
        Inbox[ğŸ“‚ inbox/]
        User -->|Commit fichiers| Inbox
    end
    
    subgraph "âš™ï¸ PROCESSING - Pipeline Automatique"
        Trigger[ğŸ”” GitHub Actions]
        Detector[ğŸ” DÃ©tecteur Format]
        
        subgraph Extracteurs
            ExtDOCX[DOCX Extractor]
            ExtPDF[PDF Extractor]
            ExtTXT[TXT Extractor]
        end
        
        LLM[ğŸ¤– LLM Analyzer]
        QualityGate[âœ… Quality Gate]
        Storage[ğŸ’¾ Storage Manager]
        
        Inbox -->|Push trigger| Trigger
        Trigger --> Detector
        Detector --> ExtDOCX
        Detector --> ExtPDF
        Detector --> ExtTXT
        
        ExtDOCX --> LLM
        ExtPDF --> LLM
        ExtTXT --> LLM
        
        LLM --> QualityGate
        QualityGate -->|ValidÃ©| Storage
        QualityGate -->|RejetÃ©| Rejected[âŒ Queue manuelle]
    end
    
    subgraph "ğŸ“š OUTPUT - Zone Machine"
        Knowledge[ğŸ“ knowledge/]
        RAG[ğŸ”® RAG Engine]
        
        Storage --> Knowledge
        Knowledge --> RAG
    end
    
    subgraph "ğŸ”§ Infrastructure"
        Ollama[ğŸ³ Ollama LLM<br/>Mistral 7B]
        Metrics[ğŸ“Š Metrics DB]
        
        LLM -.->|Appels| Ollama
        QualityGate -.->|Logs| Metrics
        Storage -.->|Logs| Metrics
    end
```

### Flux de donnÃ©es dÃ©taillÃ©

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ Support
    participant Git as ğŸ“‚ Git Repo
    participant CI as âš™ï¸ GitHub Actions
    participant Extractor as ğŸ“¤ Extracteur
    participant LLM as ğŸ¤– LLM Analyzer
    participant Ollama as ğŸ³ Ollama API
    participant QG as âœ… Quality Gate
    participant Store as ğŸ’¾ Storage
    participant KB as ğŸ“š knowledge/

    User->>Git: git push inbox/FAQ.docx
    Git->>CI: Webhook trigger
    
    activate CI
    CI->>Extractor: DÃ©tecter + Router
    activate Extractor
    Extractor->>Extractor: Extraction texte + metadata
    Extractor-->>LLM: Texte brut normalisÃ©
    deactivate Extractor
    
    activate LLM
    LLM->>Ollama: Prompt 1: Classification
    Ollama-->>LLM: Type, produits, tags
    
    LLM->>Ollama: Prompt 2: Chunking sÃ©mantique
    Ollama-->>LLM: Sections structurÃ©es
    
    LLM->>Ollama: Prompt 3: Glossaire
    Ollama-->>LLM: Termes techniques
    
    LLM->>LLM: Assembler Markdown + YAML
    LLM-->>QG: Document complet
    deactivate LLM
    
    activate QG
    QG->>QG: Validation schÃ©ma
    QG->>QG: Check qualitÃ©
    QG->>QG: DÃ©tection doublons
    
    alt Document valide
        QG-->>Store: âœ… ApprouvÃ©
        activate Store
        Store->>KB: Ã‰crire fichier
        Store->>Git: Commit automatique
        deactivate Store
    else Document invalide
        QG->>User: âš ï¸ Notification Ã©chec
    end
    deactivate QG
    deactivate CI
```

### Ã‰tats d'un document

```mermaid
stateDiagram-v2
    [*] --> Inbox: Commit humain
    
    Inbox --> Detection: CI triggered
    Detection --> Extraction: Format identifiÃ©
    
    Extraction --> ExtractionOK: SuccÃ¨s
    Extraction --> ExtractionFailed: Fichier corrompu
    
    ExtractionOK --> Enrichissement
    ExtractionFailed --> ManualQueue
    
    Enrichissement --> QualityCheck: LLM terminÃ©
    
    QualityCheck --> Approved: Score >= 0.8
    QualityCheck --> Rejected: Score < 0.8
    
    Approved --> Knowledge
    Rejected --> ManualQueue
    
    Knowledge --> RAG
    RAG --> [*]
    
    ManualQueue --> Inbox: Correction
```

---

## Composants dÃ©taillÃ©s

### 1. Extracteurs - Couche de conversion

```mermaid
flowchart TB
    Input[Fichier source] --> Detect{DÃ©tection<br/>format}
    
    Detect -->|.docx| DOCX[DOCX Extractor]
    Detect -->|.pdf| PDF[PDF Extractor]
    Detect -->|.txt/.md| TXT[TXT Extractor]
    Detect -->|.eml| Email[Email Extractor]
    
    DOCX -->|python-docx| ExtractDOCX[Texte + Tableaux<br/>+ Images]
    PDF -->|PyMuPDF| CheckPDF{PDF natif<br/>ou scannÃ©?}
    TXT -->|chardet| ExtractTXT[Texte + Encodage]
    Email -->|email parser| ExtractEmail[Corps + Metadata]
    
    CheckPDF -->|Natif| ExtractPDFNative[Texte direct]
    CheckPDF -->|ScannÃ©| OCR[Tesseract OCR]
    OCR --> ExtractPDFScan[Texte OCR]
    
    ExtractDOCX --> Normalize[Normalisation]
    ExtractPDFNative --> Normalize
    ExtractPDFScan --> Normalize
    ExtractTXT --> Normalize
    ExtractEmail --> Normalize
    
    Normalize --> Output[Texte brut<br/>+ Metadata dict]
```

**MÃ©tadonnÃ©es extraites** :
- Auteur (si disponible)
- Date de crÃ©ation/modification
- Titre (depuis metadata ou H1)
- Images (exportÃ©es vers `assets/`)

**BibliothÃ¨ques** :
- `python-docx` : Extraction DOCX
- `PyMuPDF` : PDFs natifs
- `Tesseract` : OCR pour PDFs scannÃ©s
- `chardet` : DÃ©tection encodage
- `Unstructured.io` : Extraction avancÃ©e (optionnel)

---

### 2. LLM Analyzer - Enrichissement intelligent

```mermaid
flowchart TB
    Input[Texte brut] --> Phase1[Phase 1:<br/>Classification]
    
    Phase1 -->|Prompt 1| LLM1[ğŸ¤– LLM]
    LLM1 --> R1[Type: FAQ/Procedure/etc.<br/>Produits: OSE/OSM<br/>Tags: api, auth, etc.]
    
    R1 --> Phase2[Phase 2:<br/>Chunking SÃ©mantique]
    Phase2 -->|Prompt 2| LLM2[ğŸ¤– LLM]
    LLM2 --> R2[Sections cohÃ©rentes<br/>H2/H3 structure<br/>Keywords par section]
    
    R2 --> Phase3[Phase 3:<br/>Glossaire]
    Phase3 -->|Prompt 3| LLM3[ğŸ¤– LLM]
    LLM3 --> R3[Termes techniques<br/>Acronymes<br/>Variations]
    
    R1 --> Assembler[Assembler]
    R2 --> Assembler
    R3 --> Assembler
    
    Assembler --> YAML[Frontmatter YAML]
    Assembler --> MD[Corps Markdown]
    
    YAML --> Final[Document final]
    MD --> Final
```

#### Prompts systÃ¨me

**Prompt 1 - Classification** :
```
Tu es un bibliothÃ©caire technique expert OSE/OSM.
Analyse ce document et retourne un JSON avec :
{
  "type": "FAQ|Procedure|Troubleshooting|Architecture|Release_Notes",
  "products": ["liste produits mentionnÃ©s"],
  "tags": ["max 5 tags techniques"],
  "summary": "rÃ©sumÃ© en 2 phrases"
}
```

**Prompt 2 - Chunking** :
```
DÃ©coupe ce texte en sections cohÃ©rentes.
RÃ¨gles :
- Une procÃ©dure complÃ¨te = 1 section
- Une Q&A = 1 section
- PrÃ©server la hiÃ©rarchie (H2, H3)
Retourne la structure Markdown avec titres.
```

**Prompt 3 - Glossaire** :
```
Identifie les termes techniques, acronymes, noms de produits.
Pour chaque terme :
- Forme canonique
- Variantes observÃ©es
- DÃ©finition si Ã©vidente
```

**Cache** : Utilise Redis pour Ã©viter de re-traiter des docs identiques (basÃ© sur hash du contenu source).

---

### 3. Quality Gate - Validation automatique

```mermaid
flowchart TB
    Doc[Document gÃ©nÃ©rÃ©] --> Check1{Schema YAML<br/>valide?}
    
    Check1 -->|Non| Reject1[âŒ Rejet]
    Check1 -->|Oui| Check2{MÃ©tadonnÃ©es<br/>obligatoires?}
    
    Check2 -->|Manquantes| Reject2[âŒ Rejet]
    Check2 -->|OK| Check3{Chunking<br/>cohÃ©rent?}
    
    Check3 -->|< 20 mots/chunk| Reject3[âŒ Rejet]
    Check3 -->|OK| Check4{Doublons<br/>dÃ©tectÃ©s?}
    
    Check4 -->|SimilaritÃ© > 95%| Reject4[âŒ Rejet]
    Check4 -->|OK| Score[Calcul score<br/>global]
    
    Score --> Decision{Score<br/>>= 0.8?}
    
    Decision -->|Non| Reject5[âŒ Rejet]
    Decision -->|Oui| Approve[âœ… ApprouvÃ©]
    
    Reject1 --> Log[Log raison]
    Reject2 --> Log
    Reject3 --> Log
    Reject4 --> Log
    Reject5 --> Log
    
    Approve --> Next[Stockage]
```

**CritÃ¨res de qualitÃ© pondÃ©rÃ©s** :

| CritÃ¨re | Poids | VÃ©rification |
|---------|-------|--------------|
| ComplÃ©tude mÃ©tadonnÃ©es | 30% | Tous les champs obligatoires prÃ©sents |
| QualitÃ© chunking | 25% | Chunks cohÃ©rents, mots-clÃ©s prÃ©sents |
| Richesse glossaire | 15% | Au moins 3 termes identifiÃ©s |
| ClartÃ© structure | 20% | HiÃ©rarchie titres correcte |
| CohÃ©rence technique | 10% | Produits/versions identifiÃ©s |

**Score final** = Somme pondÃ©rÃ©e â†’ Seuil d'acceptation : 0.8/1.0

---

### 4. Storage Manager - Organisation & versioning

```mermaid
flowchart TD
    Input[Doc approuvÃ©] --> Hash[Calculer SHA256<br/>fichier source]
    
    Hash --> Exists{Fichier avec<br/>ce hash existe?}
    
    Exists -->|Oui| Skip[Skip: dÃ©jÃ  traitÃ©]
    Exists -->|Non| Organize[Organiser]
    
    Organize --> ByProduct[Copie dans<br/>by_product/OSE/]
    Organize --> ByType[Copie dans<br/>by_type/FAQ/]
    
    ByProduct --> Write[Ã‰crire fichier]
    ByType --> Write
    
    Write --> UpdateIndex[MAJ index.json]
    UpdateIndex --> MergeGlossary[Fusion glossary_master.json]
    MergeGlossary --> GitCommit[Git commit auto]
```

**Organisation du dossier `knowledge/`** :

```
knowledge/
â”œâ”€â”€ by_product/
â”‚   â”œâ”€â”€ OSE/
â”‚   â”‚   â”œâ”€â”€ v3.2/
â”‚   â”‚   â”‚   â”œâ”€â”€ faq_auth_e8f2a1.md
â”‚   â”‚   â”‚   â””â”€â”€ procedure_deploy_92b3c4.md
â”‚   â”‚   â””â”€â”€ v3.3/
â”‚   â””â”€â”€ OSM/
â”‚
â”œâ”€â”€ by_type/
â”‚   â”œâ”€â”€ FAQ/
â”‚   â”œâ”€â”€ Procedures/
â”‚   â””â”€â”€ Troubleshooting/
â”‚
â”œâ”€â”€ index.json              # Index global des docs
â”œâ”€â”€ glossary_master.json    # Glossaire consolidÃ©
â””â”€â”€ archives/               # Anciennes versions
```

**Nommage** : `{type}_{sujet}_{hash-court}.md`

Exemple : `faq_auth_e8f2a1.md`

---

## Format de sortie

### Structure Markdown + YAML frontmatter

```markdown
---
# === MÃ‰TADONNÃ‰ES ===
source:
  file: "FAQ_OSE_v3.2.docx"
  hash: "sha256:e8f2a1b3c4d5..."
  author: "Support Team"
  ingestionDate: "2026-02-02T22:00:00Z"
  lastModified: "2026-01-15"

classification:
  type: "FAQ"
  products: ["OSE", "Orange Smart Energies"]
  versions: ["3.2", "3.x"]
  audience: ["L1", "L2"]
  tags: ["troubleshooting", "api", "authentication"]

quality:
  score: 0.92
  completeness: 0.89
  lastReviewed: "2026-02-02"
  reviewedBy: "pipeline_v1.0"

obsolescence:
  isObsolete: false
  deprecationDate: null
  supersededBy: null

glossary:
  OSE:
    canonical: "Orange Smart Energies"
    aliases: ["Smart Energies", "plateforme OSE"]
  JWT:
    canonical: "JSON Web Token"
    aliases: ["token", "access token"]

references:
  internal:
    - title: "Architecture OSE"
      path: "knowledge/architecture/ose_overview.md"
  external:
    - title: "JWT.io"
      url: "https://jwt.io"
---

# FAQ - Authentification API OSE v3.2

> **RÃ©sumÃ©** : Documentation des erreurs courantes d'authentification et leurs rÃ©solutions pour l'API OSE version 3.2+

---

## ğŸ” Erreurs d'Authentification

### Comment rÃ©soudre l'erreur 401 Unauthorized ?

**ProblÃ¨me** : L'erreur 401 survient quand le token JWT est invalide ou expirÃ©.

**Solution** :
1. RÃ©gÃ©nÃ©rer le token via l'endpoint `/auth/refresh`
2. Utiliser le nouveau token dans vos requÃªtes

**Tags** : `401` `JWT` `token` `authentication`
**Produits** : OSE v3.2, v3.3
**Niveau** : L1

---

## ğŸ”„ ProcÃ©dures

### Renouvellement du Token API

**Ã‰tapes** :

1. **Appeler l'endpoint de refresh**
   ```bash
   POST /auth/refresh
   Content-Type: application/json
   
   {
     "refresh_token": "votre_refresh_token"
   }
   ```

2. **RÃ©cupÃ©rer le nouveau token**
   ```json
   {
     "access_token": "nouveau_token",
     "expires_in": 3600
   }
   ```

3. **Mettre Ã  jour vos headers**
   ```bash
   Authorization: Bearer nouveau_token
   ```

**Tags** : `refresh` `token` `API`
**DifficultÃ©** : Simple
**Temps estimÃ©** : 2 minutes

---

## ğŸ“š Glossaire

- **OSE** (Orange Smart Energies) : Plateforme de gestion intelligente de l'Ã©nergie
- **JWT** (JSON Web Token) : Standard d'authentification par jeton
```

**Avantages** :
- âœ… Lisible par humains (Git review facile)
- âœ… Parsable par machines (frontmatter YAML structurÃ©)
- âœ… Versioning clair (diffs Git propres)
- âœ… MÃ©tadonnÃ©es riches pour filtrage RAG

---

## Workflow CI/CD

### GitHub Actions Pipeline

```mermaid
flowchart TB
    Trigger[Push sur inbox/**] --> Checkout[Checkout repo]
    Checkout --> Setup[Setup Python 3.11]
    Setup --> InstallDeps[Install dependencies]
    InstallDeps --> StartOllama[Start Ollama container]
    
    StartOllama --> Orchestrator[python orchestrator.py]
    
    Orchestrator --> Detect[DÃ©tecter nouveaux fichiers]
    Detect --> Extract[Extraction parallÃ¨le]
    Extract --> Enrich[Enrichissement LLM]
    Enrich --> Validate[Validation qualitÃ©]
    
    Validate --> Decision{RÃ©sultat?}
    
    Decision -->|SuccÃ¨s| Commit[Git commit + push]
    Decision -->|Ã‰chec| Notify[Notification Slack/Email]
    
    Commit --> UpdateMetrics[Update dashboard]
    Notify --> UpdateMetrics
```

**Fichier** : `.github/workflows/doc_pipeline.yml`

```yaml
name: Document Standardization Pipeline

on:
  push:
    paths:
      - 'inbox/**'

jobs:
  process:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: pip install -r pipeline/requirements.txt
      
      - name: Start Ollama
        run: |
          docker run -d -p 11434:11434 ollama/ollama
          docker exec ollama ollama pull mistral:7b
      
      - name: Run Pipeline
        run: python pipeline/orchestrator.py --input inbox/ --output knowledge/
        env:
          LLM_MODEL: "mistral:7b"
          QUALITY_THRESHOLD: "0.8"
      
      - name: Commit Results
        run: |
          git config user.name "Pipeline Bot"
          git config user.email "pipeline@ose.local"
          git add knowledge/
          git commit -m "ğŸ¤– Pipeline: $(date)" || echo "No changes"
          git push
```

**Performance** :
- Temps moyen : 15-30s par document
- ParallÃ©lisation : Plusieurs docs en simultanÃ©
- Cache LLM : RÃ©duit le temps pour docs similaires

---

## Organisation repository

### Structure complÃ¨te

```
repo-rag-support/
â”œâ”€â”€ inbox/                          # Zone humaine (write-only)
â”‚   â”œâ”€â”€ FAQ_OSE.docx
â”‚   â”œâ”€â”€ GUIDE_API.pdf
â”‚   â””â”€â”€ troubleshooting.txt
â”‚
â”œâ”€â”€ knowledge/                      # Zone bot (write-only)
â”‚   â”œâ”€â”€ by_product/
â”‚   â”œâ”€â”€ by_type/
â”‚   â”œâ”€â”€ index.json
â”‚   â””â”€â”€ glossary_master.json
â”‚
â”œâ”€â”€ pipeline/                       # Code de la pipeline
â”‚   â”œâ”€â”€ extractors/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ docx_extractor.py
â”‚   â”‚   â”œâ”€â”€ pdf_extractor.py
â”‚   â”‚   â”œâ”€â”€ text_extractor.py
â”‚   â”‚   â””â”€â”€ email_extractor.py
â”‚   â”‚
â”‚   â”œâ”€â”€ enrichment/
â”‚   â”‚   â”œâ”€â”€ llm_analyzer.py
â”‚   â”‚   â””â”€â”€ prompts/
â”‚   â”‚       â”œâ”€â”€ classify_v1.txt
â”‚   â”‚       â”œâ”€â”€ chunk_v1.txt
â”‚   â”‚       â””â”€â”€ glossary_v1.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ quality/
â”‚   â”‚   â””â”€â”€ validator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â””â”€â”€ knowledge_store.py
â”‚   â”‚
â”‚   â”œâ”€â”€ orchestrator.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ docs/                           # Documentation
â”‚   â”œâ”€â”€ DATA_CONTRACT.md
â”‚   â”œâ”€â”€ TAXONOMY.md
â”‚   â””â”€â”€ CONTRIBUTOR_GUIDE.md
â”‚
â”œâ”€â”€ tests/                          # Tests
â”‚   â”œâ”€â”€ fixtures/
â”‚   â”œâ”€â”€ test_extractors.py
â”‚   â”œâ”€â”€ test_llm_analyzer.py
â”‚   â””â”€â”€ test_validator.py
â”‚
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ doc_pipeline.yml
```

### Permissions Git

| RÃ´le | `inbox/` | `knowledge/` | `pipeline/` |
|------|----------|--------------|-------------|
| Support Team | âœ… Write | ğŸ”’ Read only | ğŸ”’ Read only |
| Pipeline Bot | ğŸ”’ Read only | âœ… Write | âœ… Read |
| Admin | âœ… Write | âœ… Write | âœ… Write |

**Protection** : Branch rules empÃªchent commits humains directs dans `knowledge/`

---

## DÃ©ploiement

### Timeline - 4 semaines

```mermaid
gantt
    title Roadmap DÃ©ploiement Pipeline
    dateFormat YYYY-MM-DD
    
    section Semaine 1: Infra
    Setup repo Git               :s1_1, 2026-02-03, 2d
    Install Ollama               :s1_2, after s1_1, 1d
    Config GitHub Actions        :s1_3, after s1_2, 2d
    
    section Semaine 2: Extracteurs
    DÃ©velopper extracteurs       :s2_1, 2026-02-08, 5d
    Tests extracteurs            :s2_2, after s2_1, 2d
    
    section Semaine 3: LLM + QG
    LLM Analyzer                 :s3_1, 2026-02-15, 4d
    Prompts systÃ¨me              :s3_2, after s3_1, 1d
    Quality Gate                 :s3_3, after s3_2, 2d
    
    section Semaine 4: IntÃ©gration
    Storage Manager              :s4_1, 2026-02-22, 2d
    Tests E2E                    :s4_2, after s4_1, 2d
    POC 5 docs rÃ©els             :milestone, s4_3, after s4_2, 0d
    Documentation                :s4_4, after s4_3, 1d
    DÃ©mo Ã©quipe                  :milestone, s4_5, after s4_4, 0d
```

### Checklist de lancement

**Phase 1 : Setup (Jours 1-3)**
- [ ] CrÃ©er repo Git
- [ ] Installer Ollama + Mistral 7B
- [ ] Configurer GitHub Actions (webhook)
- [ ] CrÃ©er structure dossiers

**Phase 2 : DÃ©veloppement (Jours 4-14)**
- [ ] ImplÃ©menter extracteurs (DOCX, PDF, TXT)
- [ ] CrÃ©er prompts LLM (classification, chunking, glossaire)
- [ ] DÃ©velopper Quality Gate
- [ ] Coder Storage Manager

**Phase 3 : Tests (Jours 15-21)**
- [ ] Tests unitaires extracteurs
- [ ] Tests LLM avec fixtures
- [ ] Tests E2E sur 10 docs historiques
- [ ] Validation qualitÃ© outputs

**Phase 4 : POC (Jours 22-28)**
- [ ] Traiter 5 documents rÃ©els de l'Ã©quipe
- [ ] Mesurer temps de traitement
- [ ] Ã‰valuer qualitÃ© des docs gÃ©nÃ©rÃ©s
- [ ] DÃ©mo Ã  l'Ã©quipe support
- [ ] Ajustements selon feedback

---

## MÃ©triques & ObservabilitÃ©

### KPIs Ã  tracker

| MÃ©trique | Objectif | Critique |
|----------|----------|----------|
| **Temps de traitement** | < 30s / doc | Moyen |
| **Taux de succÃ¨s** | > 90% | Ã‰levÃ© |
| **Score qualitÃ© moyen** | > 0.85/1.0 | Ã‰levÃ© |
| **Doublons dÃ©tectÃ©s** | < 5% | Moyen |
| **Uptime pipeline** | > 99% | Ã‰levÃ© |

### Dashboard mÃ©triques

```mermaid
flowchart LR
    subgraph Sources
        P[Pipeline Events]
        Q[Quality Checks]
        S[Storage Ops]
    end
    
    subgraph Collection
        M[Metrics Collector]
        DB[(SQLite / Prometheus)]
    end
    
    subgraph Visualisation
        D1[Pipeline Health]
        D2[Quality Trends]
        D3[Processing Time]
    end
    
    P --> M
    Q --> M
    S --> M
    
    M --> DB
    
    DB --> D1
    DB --> D2
    DB --> D3
```

**MÃ©triques collectÃ©es** :
- Total docs traitÃ©s
- Taux succÃ¨s/Ã©chec
- Temps moyen par format
- Distribution scores qualitÃ©
- Usage tokens LLM
- Taille des docs gÃ©nÃ©rÃ©s

---

## Stack Technique

| Composant | Technologie | Raison |
|-----------|-------------|--------|
| **Extraction DOCX** | python-docx | Standard, bien maintenu |
| **Extraction PDF** | PyMuPDF | Rapide, support natif + OCR |
| **OCR** | Tesseract | Open-source, multi-langue |
| **LLM** | Ollama + Mistral 7B | Local, gratuit, performant |
| **Format sortie** | Markdown + YAML | Lisible humain + machine |
| **Parsing YAML** | PyYAML | Standard Python |
| **CI/CD** | GitHub Actions | Gratuit, intÃ©grÃ© |
| **Versioning** | Git | Source de vÃ©ritÃ© unique |
| **MÃ©triques** | SQLite ou Prometheus | Simple ou scalable |
| **Language** | Python 3.11 | Ã‰cosystÃ¨me riche |

---

## Points clÃ©s

### âœ… Avantages

- **Automatisation totale** : ZÃ©ro intervention post-dÃ©pÃ´t
- **Git-native** : Versioning, review, rollback gratuits
- **QualitÃ© garantie** : Validation automatique stricte
- **Scalable** : Traite 100-1000 docs sans modifications
- **Pas de coÃ»t LLM** : ModÃ¨le local (Ollama)
- **ObservabilitÃ©** : MÃ©triques complÃ¨tes

### âš ï¸ Limitations

- NÃ©cessite que l'Ã©quipe crÃ©e des fichiers (docs brutes)
- DÃ©pend de la qualitÃ© du LLM (ajustement prompts)
- Pas adaptÃ© pour connaissance orale pure
- NÃ©cessite infra Ollama (GPU optionnel mais recommandÃ©)

### ğŸ¯ Cas d'usage idÃ©aux

- Documentation procÃ©durale existante Ã  standardiser
- Guides techniques Ã  migrer vers Git
- FAQs dispersÃ©es Ã  centraliser
- Release notes Ã  structurer
- Architectures Ã  documenter

---

## Prochaines Ã©tapes

**Validation concept** :
1. Tester extraction sur 5 docs rÃ©els
2. Valider prompts LLM avec l'Ã©quipe
3. DÃ©finir taxonomy (types, produits, tags)

**ImplÃ©mentation** :
1. Setup infra (Git + Ollama + CI/CD)
2. DÃ©velopper composants par ordre
3. Tests continus

**DÃ©ploiement** :
1. POC sur sous-ensemble de docs
2. Ajustements selon feedback
3. Rollout progressif

---

**Version** : 1.0  
**Date** : 2026-02-03  
**Ã‰quipe** : Support OSE/OSM
