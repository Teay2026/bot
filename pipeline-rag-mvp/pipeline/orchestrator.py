#!/usr/bin/env python3
"""
Orchestrateur Principal - MVP Pipeline RAG
Traite les fichiers de inbox/ et gÃ©nÃ¨re les docs dans knowledge/
"""

import sys
from pathlib import Path
import yaml
from datetime import datetime

# Ajouter le dossier parent au path
sys.path.insert(0, str(Path(__file__).parent))

from extractors import DocxExtractor
from enrichment import LLMAnalyzer
from quality import QualityGate
from storage import StorageManager


class PipelineOrchestrator:
    """Orchestrateur de la pipeline complÃ¨te"""
    
    def __init__(self, config_path: Path):
        """
        Args:
            config_path: Chemin vers config.yaml
        """
        # Charger config
        with open(config_path) as f:
            self.config = yaml.safe_load(f)
        
        # Initialiser composants
        self.extractor = DocxExtractor()
        self.analyzer = LLMAnalyzer(config_path)
        self.quality_gate = QualityGate(min_score=self.config["quality"]["min_score"])
        
        knowledge_path = Path(self.config["paths"]["knowledge"])
        self.storage = StorageManager(knowledge_path)
        
        self.inbox_path = Path(self.config["paths"]["inbox"])
    
    def process_all(self):
        """Traite tous les fichiers dans inbox/"""
        print("ğŸš€ DÃ©marrage de la pipeline RAG")
        print(f"ğŸ“‚ Inbox: {self.inbox_path}")
        print()
        
        # Trouver fichiers DOCX
        docx_files = list(self.inbox_path.glob("*.docx"))
        
        if not docx_files:
            print("âš ï¸  Aucun fichier .docx trouvÃ© dans inbox/")
            return
        
        print(f"ğŸ“„ {len(docx_files)} fichier(s) trouvÃ©(s)")
        print()
        
        stats = {
            "total": len(docx_files),
            "success": 0,
            "failed": 0
        }
        
        for docx_file in docx_files:
            success = self.process_file(docx_file)
            if success:
                stats["success"] += 1
            else:
                stats["failed"] += 1
            print()
        
        # Rapport final
        print("=" * 60)
        print("ğŸ“Š RAPPORT FINAL")
        print(f"âœ… SuccÃ¨s: {stats['success']}/{stats['total']}")
        print(f"âŒ Ã‰checs: {stats['failed']}/{stats['total']}")
        print("=" * 60)
    
    def process_file(self, file_path: Path) -> bool:
        """
        Traite un fichier via la pipeline complÃ¨te
        
        Args:
            file_path: Chemin vers le fichier
            
        Returns:
            True si succÃ¨s, False sinon
        """
        print(f"ğŸ”„ Traitement: {file_path.name}")
        
        # 1. EXTRACTION
        print("  ğŸ“¤ Extraction...")
        extract_result = self.extractor.extract(file_path)
        
        if not extract_result["success"]:
            print(f"  âŒ Ã‰chec extraction: {extract_result['error']}")
            return False
        
        text = extract_result["text"]
        metadata = extract_result["metadata"]
        print(f"  âœ… {len(text)} caractÃ¨res extraits")
        
        # 2. ENRICHISSEMENT LLM
        print("  ğŸ¤– Enrichissement LLM...")
        analyze_result = self.analyzer.analyze(text, metadata)
        
        if not analyze_result["success"]:
            print(f"  âŒ Ã‰chec analyse: {analyze_result['error']}")
            return False
        
        document = analyze_result["document"]
        print("  âœ… Document enrichi gÃ©nÃ©rÃ©")
        
        # 3. QUALITY GATE
        print("  âœ… Validation qualitÃ©...")
        validation = self.quality_gate.validate(document)
        
        print(f"  ğŸ“Š Score: {validation['score']}")
        
        if not validation["is_valid"]:
            print(f"  âŒ Document rejetÃ©:")
            for error in validation["errors"]:
                print(f"     - {error}")
            return False
        
        print(f"  âœ… Validation OK")
        
        # 4. STORAGE
        print("  ğŸ’¾ Stockage...")
        
        # Extraire mÃ©tadonnÃ©es pour storage
        import yaml as yaml_parser
        parts = document.split("---")
        frontmatter = yaml_parser.safe_load(parts[1])
        classification = frontmatter.get("classification", {})
        
        storage_result = self.storage.store(
            document=document,
            source_file=file_path.name,
            metadata=classification
        )
        
        if not storage_result["success"]:
            print(f"  âŒ Ã‰chec stockage: {storage_result['error']}")
            return False
        
        print(f"  âœ… StockÃ©: {storage_result['filename']}")
        for path in storage_result["paths"]:
            print(f"     ğŸ“ {path}")
        
        return True


def main():
    """Point d'entrÃ©e principal"""
    # Chemin config
    base_dir = Path(__file__).parent.parent
    config_path = base_dir / "config.yaml"
    
    if not config_path.exists():
        print(f"âŒ Erreur: {config_path} introuvable")
        sys.exit(1)
    
    # Lancer orchestrateur
    orchestrator = PipelineOrchestrator(config_path)
    orchestrator.process_all()


if __name__ == "__main__":
    main()
